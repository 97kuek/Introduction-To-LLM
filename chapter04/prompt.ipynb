{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMYxx4q84n+978JeGNDppg1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 大規模言語モデルの進展"],"metadata":{"id":"IpgSK9YSFNEJ"}},{"cell_type":"markdown","source":["## 4.1 モデルの大規模化とその効果\n","大規模言語モデルの開発が進むにつれて、**モデルのパラメータ数**と**コーパス**の容量が飛躍的に増加していく。モデルの規模を大きくすることで性能が比例して改善していくという**スケール則**からこのようなことが起こっている。訓練に必要な計算ほとんどは浮動小数点演算であるため、**FLOPS**で計測されるのが一般的。\n","$$\n","FLOPS \\approx 6*パラメータ数*トークン数\n","$$\n","大規模なモデルを訓練する際には多額の予算が必要になり、確保できる予算に応じて訓練に使える計算量が決まる。また、大規模言語モデルが一定の規模を超えるとタスクの性能が飛躍的に向上する現象も確認されている。このような能力を**創発的能力**という。"],"metadata":{"id":"SxUtnjxuFRpZ"}},{"cell_type":"markdown","source":["## 4.2 プロンプトによる言語モデルの制御\n","従来は**ファインチューニング**を行わないと解けないと思われていた多くのタスクが、モデルにプロンプトと呼ばれるテキストを入力して後続するテキストを予測するという単純な方法で解けることがわかってきた。自然言語処理のタスク入力と出力をテキストで表現することにより、あらゆるタスクを同一のフォーマットで解くことが可能になる。"],"metadata":{"id":"LRE8FvUcGdNi"}},{"cell_type":"markdown","source":["### 4.2.1 文脈内学習\n","プロンプトを使ってタスクを解く際に有効な方法の一つに例示を与える方法がある。例示を一つ与える設定を**one-shot学習**、複数与える設定を**few-shot学習**、例示を与えない設定を**zero-shot学習**という。"],"metadata":{"id":"hFYfaEXZHcLx"}}]}